{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDuUDfinmgcK"
      },
      "source": [
        "# SegNet implementation in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndbfRG50mTEl"
      },
      "source": [
        "Move the frame to colab [**Done**]\n",
        "\n",
        "Mount data [**done**]\n",
        "\n",
        "Fix the training function [**Done**]\n",
        "\n",
        "Report training accuracy [**Done**]\n",
        "\n",
        "Learning Rate decay and cooldown [**Done**]\n",
        "\n",
        "Save checkpints [**Done**]\n",
        "\n",
        "Visualize an output [**On**]\n",
        "\n",
        "Calculate class weights [**Pending**]\n",
        "\n",
        "Try different loss functions (Focal, boundry) [**Pending**]\n",
        "\n",
        "Quantitive evaluation (IOU, accuracy, etc) [**Pending**]\n",
        "\n",
        "Video visualization [**Pending**]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDvmFc-qItn"
      },
      "source": [
        "# import necessary libraries\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torchsummary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U75vySzlz7k",
        "outputId": "9494f5f5-3550-493d-db32-340396e2a965"
      },
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# !ls gdrive/MyDrive"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF_CVjz0m2bO",
        "outputId": "a2d7e97e-b63f-4695-a4f0-87247ff052b5"
      },
      "source": [
        "# get the patht to the camvid data\n",
        "camvid_path = r'/content/gdrive/MyDrive/CamVid'\n",
        "!ls '/content/gdrive/MyDrive/CamVid'\n",
        "\n",
        "# get the path to the scripts\n",
        "!ls gdrive/MyDrive/Segmentation/code\n",
        "\n",
        "# access necessary code\n",
        "from gdrive.MyDrive.Segmentation.code.model import SegNet\n",
        "import gdrive.MyDrive.Segmentation.code.data as data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_dict.csv\ttest  test_labels  train  train_labels\tval  val_labels\n",
            "data.py  eval.py  loss.py  model.py  __pycache__  train.py  train_resnet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw1PXTUtNI_a"
      },
      "source": [
        "## Reporting/Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bryrf46NGLG"
      },
      "source": [
        "def avg_pixelwise_accuracy(model, dataset):\n",
        "\n",
        "  if not dataset:\n",
        "    return -1\n",
        "\n",
        "  # change to eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # get the dataloader using large batch since only forward pass required\n",
        "  loader = DataLoader(dataset=dataset, \n",
        "                      batch_size=16, \n",
        "                      )\n",
        "  \n",
        "  correct, total = 0, 0\n",
        "  for i, batch in enumerate(loader):\n",
        "\n",
        "    # mount to GPU if available [Need to fix y]\n",
        "    imgs, labels = batch['X'].to(DEVICE), batch['y'][:, 1, :, :].to(DEVICE)\n",
        "\n",
        "    # argmax X along dim 1\n",
        "    out = model(imgs)\n",
        "    predicted = torch.argmax(out, dim=1)\n",
        "    total += labels.nelement()\n",
        "    correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "  return correct / total\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXHZtu7LprhL"
      },
      "source": [
        "## Save/Load checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3re_4_PpvBt"
      },
      "source": [
        "def save_checkpoints(model, filename, epoch, optimizer, loss, train_acc, valid_acc):\n",
        "\n",
        "  dirname = \"/content/gdrive/MyDrive/Segmentation/check_points\"\n",
        "\n",
        "  save_path = os.path.join(dirname, filename)\n",
        "  print(save_path)\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'train_acc': train_acc,\n",
        "            'valid_acc': valid_acc\n",
        "            }, save_path)\n",
        "\n",
        "\n",
        "def load_checkpoints(filename, transfer_learning=True):\n",
        "\n",
        "  dirname = \"/content/gdrive/MyDrive/Segmentation/check_points\"\n",
        "  file_path = os.path.join(dirname, filename)\n",
        "  checkpoint = torch.load(file_path)\n",
        "  model = SegNet(IN_CHANNELS, NUM_CLASS, transfer_learning=transfer_learning)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "  print(\"Model Loaded: Epoch#{}\\tLoss:{:.4f}\\tTrainAcc:{:.4f}\\tValidAcc:{:.4f}\".format(\n",
        "      checkpoint['epoch'],\n",
        "      checkpoint['loss'],\n",
        "      checkpoint['train_acc'],\n",
        "      checkpoint['valid_acc'],\n",
        "  ))\n",
        "  return model\n",
        "\n",
        "\n",
        "# model2 = load_checkpoints(\"Epoch1_loss59.1495_trainacc31.217_valacc28.866.pth\")\n",
        "# model2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU31sGl-NPht"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvuSR1U1zlRk"
      },
      "source": [
        "# train function\n",
        "def train(model, optimizer, loss_fn, X_train, y_train, X_valid=None, y_valid=None):\n",
        "\n",
        "  # get the dataloader\n",
        "  train_dataset = data.CamVidDataset(X_train, y_train)\n",
        "  train_loader = DataLoader(dataset=train_dataset, \n",
        "                            batch_size=BATCH_SIZE, \n",
        "                            num_workers=NUM_WORKERS,\n",
        "                            pin_memory=False,\n",
        "                            shuffle=True,\n",
        "                            drop_last=True,\n",
        "                            worker_init_fn=None\n",
        "                            )\n",
        "\n",
        "  valid_dataset = data.CamVidDataset(X_valid, y_valid) if X_valid is not None else None\n",
        "\n",
        "  \n",
        "  # for plotting and logging\n",
        "  iters, losses, train_acc, val_acc, iter_counter = [], [], [], [], 0\n",
        "\n",
        "  # for checkpoints\n",
        "  checkpoint_path_template = \"Epoch{}_loss{:.4f}_trainacc{:.3f}_valacc{:.3f}.pth\"\n",
        "  acc_recoder, save_gap = 97.7, 0.15\n",
        "  \n",
        "  # start training\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    # visualize an segmentation\n",
        "\n",
        "\n",
        "\n",
        "    # Learning Rate Decay [Optional]\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      optimizer.param_groups[0]['lr'] /= 3\n",
        "      print(\"<=============== Learning Rate {} -> {}===== ==========>\".format(optimizer.param_groups[0]['lr'] * 3, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "    epoch_loss = 0\n",
        "    t_start = time.time()\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "      # mount to GPU if available [Need to fix y]\n",
        "      imgs, labels = batch['X'].to(DEVICE), batch['y'][:, 1, :, :].to(DEVICE)\n",
        "\n",
        "      # change the mode to training mode and step training\n",
        "      model.train()\n",
        "      out = model(imgs)\n",
        "      loss = loss_fn(out, labels)   # note: soft-max should not be used here since it's included in nn.CrossEntropyLoss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      iter_counter += 1\n",
        "\n",
        "      # save the current training information, TODO\n",
        "      losses.append(loss)\n",
        "      epoch_loss += loss\n",
        "\n",
        "    delta = time.time() - t_start\n",
        "\n",
        "    # train_acc = avg_pixelwise_accuracy(model, train_dataset)\n",
        "    train_acc = avg_pixelwise_accuracy(model, train_dataset) * 100\n",
        "    valid_acc = avg_pixelwise_accuracy(model, valid_dataset) * 100\n",
        "    print(\"Epoch #{}\\tLoss: {:.8f}\\tTrain Acc: {:.6f}%\\tValid Acc: {:.6f}%\\tTime: {:.2f}s\".format(epoch+1, epoch_loss, train_acc, valid_acc, delta))\n",
        "\n",
        "    # Save checkpoints\n",
        "    if train_acc > acc_recoder + save_gap:\n",
        "      acc_recoder = train_acc\n",
        "      checkpoint_name = checkpoint_path_template.format(epoch+1, epoch_loss, train_acc, valid_acc)\n",
        "      save_checkpoints(model, checkpoint_name, epoch+1, optimizer, epoch_loss, train_acc, valid_acc)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4yr0ZxiqVsQ",
        "outputId": "323d7f75-6232-46f0-e113-85c9406e7291"
      },
      "source": [
        "# load the dataset\n",
        "X_train, y_train = data.load_data(camvid_path+\"/train\")\n",
        "X_valid, y_valid = data.load_data(camvid_path+\"/val\")\n",
        "X_test, y_test = data.load_data(camvid_path+\"/test\")\n",
        "\n",
        "print(\"Loaded {} training samples, {} validation samples, {} testing samples\".format(len(X_train), len(X_valid), len(X_test)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 367 training samples, 101 validation samples, 233 testing samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz4ePSWVxUA6"
      },
      "source": [
        "# for reproduction\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Pre config\n",
        "IN_CHANNELS = 3\n",
        "NUM_CLASS = 2\n",
        "\n",
        "# training parameters\n",
        "NUM_EPOCHS = 200\n",
        "LEARNING_RATE = 0.1   # will decrease with epoch growing larger\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "LABEL_WEIGHTS = torch.FloatTensor([0.5, 2.3])\n",
        "\n",
        "#\n",
        "WEIGHT_DECAY = 0.0005\n",
        "NUM_WORKERS = 16\n",
        "PIN_MEMORY = False\n",
        "\n",
        "#\n",
        "model = SegNet(3,2, transfer_learning=True).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss(weight=LABEL_WEIGHTS).to(DEVICE)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81zp76Hy3rTo",
        "outputId": "fc4341fb-04b4-4620-eb20-84bc3bab9283"
      },
      "source": [
        "# Launch training\n",
        "torch.cuda.empty_cache()\n",
        "train(model, optimizer, loss, X_train, y_train, X_valid, y_valid)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\tLoss: 48.54034805\tTrain Acc: 31.215397%\tValid Acc: 28.865068%\tTime: 8.57s\n",
            "Epoch #2\tLoss: 22.10857201\tTrain Acc: 58.036225%\tValid Acc: 62.433048%\tTime: 8.51s\n",
            "Epoch #3\tLoss: 10.51165962\tTrain Acc: 86.396935%\tValid Acc: 90.604676%\tTime: 8.55s\n",
            "Epoch #4\tLoss: 7.55886269\tTrain Acc: 91.002559%\tValid Acc: 87.954992%\tTime: 8.56s\n",
            "Epoch #5\tLoss: 6.73101377\tTrain Acc: 94.106141%\tValid Acc: 91.291722%\tTime: 8.54s\n",
            "Epoch #6\tLoss: 5.90004253\tTrain Acc: 92.814763%\tValid Acc: 88.709525%\tTime: 8.56s\n",
            "Epoch #7\tLoss: 5.52414322\tTrain Acc: 95.314037%\tValid Acc: 95.957477%\tTime: 8.54s\n",
            "Epoch #8\tLoss: 5.15556908\tTrain Acc: 91.782772%\tValid Acc: 87.428371%\tTime: 8.55s\n",
            "Epoch #9\tLoss: 5.19527054\tTrain Acc: 95.640169%\tValid Acc: 95.926221%\tTime: 8.59s\n",
            "Epoch #10\tLoss: 5.59613466\tTrain Acc: 95.733177%\tValid Acc: 95.739610%\tTime: 8.63s\n",
            "Epoch #11\tLoss: 4.94937801\tTrain Acc: 94.066700%\tValid Acc: 92.559833%\tTime: 8.63s\n",
            "Epoch #12\tLoss: 4.87129259\tTrain Acc: 95.818430%\tValid Acc: 95.964364%\tTime: 8.64s\n",
            "Epoch #13\tLoss: 4.63853645\tTrain Acc: 95.804452%\tValid Acc: 93.652758%\tTime: 8.63s\n",
            "Epoch #14\tLoss: 4.39815998\tTrain Acc: 94.131013%\tValid Acc: 88.827091%\tTime: 8.61s\n",
            "Epoch #15\tLoss: 4.05101728\tTrain Acc: 96.049128%\tValid Acc: 95.393561%\tTime: 8.63s\n",
            "Epoch #16\tLoss: 3.81037951\tTrain Acc: 95.906605%\tValid Acc: 95.870417%\tTime: 8.59s\n",
            "Epoch #17\tLoss: 3.64652944\tTrain Acc: 93.884013%\tValid Acc: 92.042940%\tTime: 8.61s\n",
            "Epoch #18\tLoss: 3.80004025\tTrain Acc: 95.500851%\tValid Acc: 96.076425%\tTime: 8.64s\n",
            "Epoch #19\tLoss: 3.57110047\tTrain Acc: 93.765189%\tValid Acc: 91.088655%\tTime: 8.64s\n",
            "<=============== Learning Rate 0.1 -> 0.03333333333333333===== ==========>\n",
            "Epoch #20\tLoss: 3.32027006\tTrain Acc: 95.452373%\tValid Acc: 94.570755%\tTime: 8.58s\n",
            "Epoch #21\tLoss: 3.20556283\tTrain Acc: 96.248557%\tValid Acc: 96.319924%\tTime: 8.63s\n",
            "Epoch #22\tLoss: 2.95460796\tTrain Acc: 96.672655%\tValid Acc: 96.679352%\tTime: 8.59s\n",
            "Epoch #23\tLoss: 2.98439050\tTrain Acc: 96.474671%\tValid Acc: 96.251886%\tTime: 8.61s\n",
            "Epoch #24\tLoss: 2.96825790\tTrain Acc: 96.828759%\tValid Acc: 96.846467%\tTime: 8.60s\n",
            "Epoch #25\tLoss: 2.89044213\tTrain Acc: 96.292457%\tValid Acc: 96.334349%\tTime: 8.60s\n",
            "Epoch #26\tLoss: 2.81164837\tTrain Acc: 93.463792%\tValid Acc: 87.501796%\tTime: 8.58s\n",
            "Epoch #27\tLoss: 3.25204563\tTrain Acc: 96.269415%\tValid Acc: 96.539310%\tTime: 8.58s\n",
            "Epoch #28\tLoss: 3.33982873\tTrain Acc: 96.348331%\tValid Acc: 96.459137%\tTime: 8.59s\n",
            "Epoch #29\tLoss: 2.82316661\tTrain Acc: 95.192101%\tValid Acc: 93.405332%\tTime: 8.59s\n",
            "Epoch #30\tLoss: 2.85246754\tTrain Acc: 96.578110%\tValid Acc: 96.310117%\tTime: 8.59s\n",
            "Epoch #31\tLoss: 2.78239250\tTrain Acc: 97.148207%\tValid Acc: 97.420880%\tTime: 8.56s\n",
            "Epoch #32\tLoss: 2.73169208\tTrain Acc: 96.890477%\tValid Acc: 96.389462%\tTime: 8.55s\n",
            "Epoch #33\tLoss: 2.94261122\tTrain Acc: 97.144797%\tValid Acc: 97.127261%\tTime: 8.60s\n",
            "Epoch #34\tLoss: 2.67160726\tTrain Acc: 95.684759%\tValid Acc: 96.801417%\tTime: 8.63s\n",
            "Epoch #35\tLoss: 2.76817179\tTrain Acc: 96.479927%\tValid Acc: 96.225050%\tTime: 8.57s\n",
            "Epoch #36\tLoss: 2.73668647\tTrain Acc: 96.510213%\tValid Acc: 96.392481%\tTime: 8.61s\n",
            "Epoch #37\tLoss: 2.66083908\tTrain Acc: 97.150874%\tValid Acc: 97.155616%\tTime: 8.56s\n",
            "Epoch #38\tLoss: 2.73049688\tTrain Acc: 96.501085%\tValid Acc: 96.132011%\tTime: 8.56s\n",
            "Epoch #39\tLoss: 2.49482727\tTrain Acc: 97.708339%\tValid Acc: 97.770324%\tTime: 8.55s\n",
            "<=============== Learning Rate 0.03333333333333333 -> 0.011111111111111112===== ==========>\n",
            "Epoch #40\tLoss: 2.39138460\tTrain Acc: 97.417429%\tValid Acc: 97.413560%\tTime: 8.58s\n",
            "Epoch #41\tLoss: 2.34765649\tTrain Acc: 97.046250%\tValid Acc: 97.022737%\tTime: 8.58s\n",
            "Epoch #42\tLoss: 2.22887349\tTrain Acc: 97.303742%\tValid Acc: 97.340549%\tTime: 8.57s\n",
            "Epoch #43\tLoss: 2.22746253\tTrain Acc: 96.964125%\tValid Acc: 96.801417%\tTime: 8.71s\n",
            "Epoch #44\tLoss: 2.16836929\tTrain Acc: 97.365193%\tValid Acc: 97.388776%\tTime: 8.74s\n",
            "Epoch #45\tLoss: 2.15110493\tTrain Acc: 97.487417%\tValid Acc: 97.436962%\tTime: 8.74s\n",
            "Epoch #46\tLoss: 2.18004441\tTrain Acc: 97.613773%\tValid Acc: 97.502553%\tTime: 8.75s\n",
            "Epoch #47\tLoss: 2.13518381\tTrain Acc: 97.443381%\tValid Acc: 97.304676%\tTime: 8.72s\n",
            "Epoch #48\tLoss: 2.08485031\tTrain Acc: 97.356547%\tValid Acc: 97.533257%\tTime: 8.74s\n",
            "Epoch #49\tLoss: 2.18168950\tTrain Acc: 97.157260%\tValid Acc: 97.041187%\tTime: 8.73s\n",
            "Epoch #50\tLoss: 2.11575723\tTrain Acc: 96.984696%\tValid Acc: 96.923562%\tTime: 8.72s\n",
            "Epoch #51\tLoss: 2.10854197\tTrain Acc: 97.691901%\tValid Acc: 97.416381%\tTime: 8.74s\n",
            "Epoch #52\tLoss: 2.05971980\tTrain Acc: 97.201594%\tValid Acc: 97.023763%\tTime: 8.73s\n",
            "Epoch #53\tLoss: 2.13581443\tTrain Acc: 97.788547%\tValid Acc: 97.410620%\tTime: 8.75s\n",
            "Epoch #54\tLoss: 2.08686304\tTrain Acc: 97.980645%\tValid Acc: 97.815669%\tTime: 8.73s\n",
            "/content/gdrive/MyDrive/Segmentation/check_points/Epoch54_loss2.0869_trainacc97.981_valacc97.816.pth\n",
            "Epoch #55\tLoss: 1.97806346\tTrain Acc: 97.181333%\tValid Acc: 97.010483%\tTime: 9.03s\n",
            "Epoch #56\tLoss: 1.99563551\tTrain Acc: 97.758652%\tValid Acc: 97.619607%\tTime: 9.19s\n",
            "Epoch #57\tLoss: 2.23133636\tTrain Acc: 96.750713%\tValid Acc: 96.317655%\tTime: 8.96s\n",
            "Epoch #58\tLoss: 2.09637094\tTrain Acc: 97.486982%\tValid Acc: 97.037517%\tTime: 8.97s\n",
            "Epoch #59\tLoss: 1.93545961\tTrain Acc: 97.237566%\tValid Acc: 96.996848%\tTime: 8.98s\n",
            "<=============== Learning Rate 0.011111111111111112 -> 0.003703703703703704===== ==========>\n",
            "Epoch #60\tLoss: 1.79692948\tTrain Acc: 97.900111%\tValid Acc: 97.388302%\tTime: 8.94s\n",
            "Epoch #61\tLoss: 1.78662777\tTrain Acc: 97.752570%\tValid Acc: 97.240407%\tTime: 8.96s\n",
            "Epoch #62\tLoss: 1.77377141\tTrain Acc: 97.939802%\tValid Acc: 97.400793%\tTime: 8.93s\n",
            "Epoch #63\tLoss: 1.76670039\tTrain Acc: 97.872035%\tValid Acc: 97.270183%\tTime: 8.96s\n",
            "Epoch #64\tLoss: 1.82049191\tTrain Acc: 97.707579%\tValid Acc: 97.060979%\tTime: 8.99s\n",
            "Epoch #65\tLoss: 1.80769336\tTrain Acc: 97.848391%\tValid Acc: 97.393886%\tTime: 8.96s\n",
            "Epoch #66\tLoss: 1.76125205\tTrain Acc: 97.831117%\tValid Acc: 97.240821%\tTime: 8.98s\n",
            "Epoch #67\tLoss: 1.72812343\tTrain Acc: 98.108913%\tValid Acc: 97.611733%\tTime: 8.94s\n",
            "Epoch #68\tLoss: 1.76459670\tTrain Acc: 97.903907%\tValid Acc: 97.295026%\tTime: 8.97s\n",
            "Epoch #69\tLoss: 1.73267770\tTrain Acc: 97.793907%\tValid Acc: 97.198929%\tTime: 9.00s\n",
            "Epoch #70\tLoss: 1.72295153\tTrain Acc: 97.948502%\tValid Acc: 97.402904%\tTime: 8.93s\n",
            "Epoch #71\tLoss: 1.69292819\tTrain Acc: 98.052881%\tValid Acc: 97.401720%\tTime: 8.95s\n",
            "Epoch #72\tLoss: 1.65254998\tTrain Acc: 97.886752%\tValid Acc: 97.442941%\tTime: 8.96s\n",
            "Epoch #73\tLoss: 1.67181516\tTrain Acc: 97.990675%\tValid Acc: 97.402470%\tTime: 8.96s\n",
            "Epoch #74\tLoss: 1.69227016\tTrain Acc: 97.882962%\tValid Acc: 97.264619%\tTime: 8.98s\n",
            "Epoch #75\tLoss: 1.66450799\tTrain Acc: 98.043481%\tValid Acc: 97.552339%\tTime: 8.97s\n",
            "Epoch #76\tLoss: 1.70107281\tTrain Acc: 97.829629%\tValid Acc: 97.175211%\tTime: 8.92s\n",
            "Epoch #77\tLoss: 1.66810262\tTrain Acc: 97.817084%\tValid Acc: 97.246997%\tTime: 8.96s\n",
            "Epoch #78\tLoss: 1.63408744\tTrain Acc: 98.118481%\tValid Acc: 97.613549%\tTime: 8.97s\n",
            "Epoch #79\tLoss: 1.60241330\tTrain Acc: 98.000852%\tValid Acc: 97.422992%\tTime: 8.96s\n",
            "<=============== Learning Rate 0.003703703703703704 -> 0.0012345679012345679===== ==========>\n",
            "Epoch #80\tLoss: 1.57010424\tTrain Acc: 98.114398%\tValid Acc: 97.452709%\tTime: 8.92s\n",
            "Epoch #81\tLoss: 1.56779528\tTrain Acc: 98.093213%\tValid Acc: 97.407324%\tTime: 8.91s\n",
            "Epoch #82\tLoss: 1.56780660\tTrain Acc: 98.056655%\tValid Acc: 97.385599%\tTime: 8.91s\n",
            "Epoch #83\tLoss: 1.51796234\tTrain Acc: 98.098649%\tValid Acc: 97.453025%\tTime: 8.93s\n",
            "Epoch #84\tLoss: 1.54734528\tTrain Acc: 98.045811%\tValid Acc: 97.403595%\tTime: 8.91s\n",
            "Epoch #85\tLoss: 1.55063748\tTrain Acc: 98.068716%\tValid Acc: 97.426267%\tTime: 8.90s\n",
            "Epoch #86\tLoss: 1.54908025\tTrain Acc: 98.140105%\tValid Acc: 97.451841%\tTime: 8.88s\n",
            "/content/gdrive/MyDrive/Segmentation/check_points/Epoch86_loss1.5491_trainacc98.140_valacc97.452.pth\n",
            "Epoch #87\tLoss: 1.54774308\tTrain Acc: 98.101880%\tValid Acc: 97.438403%\tTime: 8.99s\n",
            "Epoch #88\tLoss: 1.53875673\tTrain Acc: 98.072322%\tValid Acc: 97.435798%\tTime: 9.03s\n",
            "Epoch #89\tLoss: 1.50280690\tTrain Acc: 98.003920%\tValid Acc: 97.355369%\tTime: 8.94s\n",
            "Epoch #90\tLoss: 1.56143332\tTrain Acc: 98.236437%\tValid Acc: 97.548372%\tTime: 8.92s\n",
            "Epoch #91\tLoss: 1.53592908\tTrain Acc: 98.193199%\tValid Acc: 97.441975%\tTime: 8.91s\n",
            "Epoch #92\tLoss: 1.62109661\tTrain Acc: 98.082233%\tValid Acc: 97.294513%\tTime: 8.94s\n",
            "Epoch #93\tLoss: 1.54032564\tTrain Acc: 98.147561%\tValid Acc: 97.491503%\tTime: 8.90s\n",
            "Epoch #94\tLoss: 1.55776727\tTrain Acc: 98.078654%\tValid Acc: 97.482979%\tTime: 8.88s\n",
            "Epoch #95\tLoss: 1.51459301\tTrain Acc: 98.133464%\tValid Acc: 97.551904%\tTime: 8.88s\n",
            "Epoch #96\tLoss: 1.59040141\tTrain Acc: 98.093420%\tValid Acc: 97.430806%\tTime: 8.87s\n",
            "Epoch #97\tLoss: 1.55367351\tTrain Acc: 98.260608%\tValid Acc: 97.514176%\tTime: 8.89s\n",
            "Epoch #98\tLoss: 1.55742586\tTrain Acc: 97.986222%\tValid Acc: 97.320166%\tTime: 8.87s\n",
            "Epoch #99\tLoss: 1.56904960\tTrain Acc: 97.954600%\tValid Acc: 97.360874%\tTime: 8.91s\n",
            "<=============== Learning Rate 0.0012345679012345679 -> 0.00041152263374485596===== ==========>\n",
            "Epoch #100\tLoss: 1.53674817\tTrain Acc: 98.134523%\tValid Acc: 97.326460%\tTime: 8.87s\n",
            "Epoch #101\tLoss: 1.48586440\tTrain Acc: 98.161512%\tValid Acc: 97.422558%\tTime: 8.89s\n",
            "Epoch #102\tLoss: 1.50179625\tTrain Acc: 98.198418%\tValid Acc: 97.513801%\tTime: 8.88s\n",
            "Epoch #103\tLoss: 1.48420823\tTrain Acc: 98.164445%\tValid Acc: 97.449019%\tTime: 8.91s\n",
            "Epoch #104\tLoss: 1.46707726\tTrain Acc: 98.249584%\tValid Acc: 97.551944%\tTime: 8.90s\n",
            "Epoch #105\tLoss: 1.51813698\tTrain Acc: 98.217218%\tValid Acc: 97.517826%\tTime: 8.87s\n",
            "Epoch #106\tLoss: 1.52614605\tTrain Acc: 98.136369%\tValid Acc: 97.427333%\tTime: 8.85s\n",
            "Epoch #107\tLoss: 1.51883686\tTrain Acc: 98.174345%\tValid Acc: 97.419618%\tTime: 8.88s\n",
            "Epoch #108\tLoss: 1.47659087\tTrain Acc: 98.231994%\tValid Acc: 97.542926%\tTime: 8.90s\n",
            "Epoch #109\tLoss: 1.46745872\tTrain Acc: 98.203083%\tValid Acc: 97.498903%\tTime: 8.85s\n",
            "Epoch #110\tLoss: 1.52884626\tTrain Acc: 98.159563%\tValid Acc: 97.446454%\tTime: 8.86s\n",
            "Epoch #111\tLoss: 1.46564639\tTrain Acc: 98.189197%\tValid Acc: 97.462398%\tTime: 8.87s\n",
            "Epoch #112\tLoss: 1.47396469\tTrain Acc: 98.239972%\tValid Acc: 97.535526%\tTime: 8.85s\n",
            "Epoch #113\tLoss: 1.48625338\tTrain Acc: 98.211456%\tValid Acc: 97.464983%\tTime: 8.88s\n",
            "Epoch #114\tLoss: 1.47291231\tTrain Acc: 98.182458%\tValid Acc: 97.429050%\tTime: 8.88s\n",
            "Epoch #115\tLoss: 1.47671151\tTrain Acc: 98.122918%\tValid Acc: 97.421847%\tTime: 8.88s\n",
            "Epoch #116\tLoss: 1.46277523\tTrain Acc: 98.093892%\tValid Acc: 97.293921%\tTime: 8.85s\n",
            "Epoch #117\tLoss: 1.45211375\tTrain Acc: 98.174877%\tValid Acc: 97.389683%\tTime: 8.84s\n",
            "Epoch #118\tLoss: 1.48728669\tTrain Acc: 98.166720%\tValid Acc: 97.367011%\tTime: 8.89s\n",
            "Epoch #119\tLoss: 1.47464585\tTrain Acc: 98.201687%\tValid Acc: 97.477355%\tTime: 8.87s\n",
            "<=============== Learning Rate 0.00041152263374485596 -> 0.00013717421124828533===== ==========>\n",
            "Epoch #120\tLoss: 1.44036448\tTrain Acc: 98.217615%\tValid Acc: 97.464253%\tTime: 8.88s\n",
            "Epoch #121\tLoss: 1.43995488\tTrain Acc: 98.255981%\tValid Acc: 97.500481%\tTime: 8.84s\n",
            "Epoch #122\tLoss: 1.45687735\tTrain Acc: 98.202540%\tValid Acc: 97.474139%\tTime: 8.85s\n",
            "Epoch #123\tLoss: 1.47314966\tTrain Acc: 98.179976%\tValid Acc: 97.420111%\tTime: 8.83s\n",
            "Epoch #124\tLoss: 1.43012083\tTrain Acc: 98.202529%\tValid Acc: 97.440258%\tTime: 8.85s\n",
            "Epoch #125\tLoss: 1.45651722\tTrain Acc: 98.249508%\tValid Acc: 97.491543%\tTime: 8.85s\n",
            "Epoch #126\tLoss: 1.50120652\tTrain Acc: 98.244756%\tValid Acc: 97.521773%\tTime: 8.90s\n",
            "Epoch #127\tLoss: 1.46662247\tTrain Acc: 98.183924%\tValid Acc: 97.464253%\tTime: 8.87s\n",
            "Epoch #128\tLoss: 1.41057312\tTrain Acc: 98.214090%\tValid Acc: 97.493141%\tTime: 8.86s\n",
            "Epoch #129\tLoss: 1.47596514\tTrain Acc: 98.205608%\tValid Acc: 97.441363%\tTime: 8.82s\n",
            "Epoch #130\tLoss: 1.47343397\tTrain Acc: 98.194323%\tValid Acc: 97.400694%\tTime: 8.88s\n",
            "Epoch #131\tLoss: 1.49398875\tTrain Acc: 98.166188%\tValid Acc: 97.393294%\tTime: 8.92s\n",
            "Epoch #132\tLoss: 1.46262074\tTrain Acc: 98.244506%\tValid Acc: 97.481972%\tTime: 9.10s\n",
            "Epoch #133\tLoss: 1.44153702\tTrain Acc: 98.212320%\tValid Acc: 97.435798%\tTime: 9.08s\n",
            "Epoch #134\tLoss: 1.43054008\tTrain Acc: 98.251028%\tValid Acc: 97.503895%\tTime: 9.10s\n",
            "Epoch #135\tLoss: 1.42641616\tTrain Acc: 98.230099%\tValid Acc: 97.468890%\tTime: 9.12s\n",
            "Epoch #136\tLoss: 1.42650163\tTrain Acc: 98.198602%\tValid Acc: 97.488425%\tTime: 9.11s\n",
            "Epoch #137\tLoss: 1.44146609\tTrain Acc: 98.237892%\tValid Acc: 97.439686%\tTime: 9.14s\n",
            "Epoch #138\tLoss: 1.44367170\tTrain Acc: 98.181502%\tValid Acc: 97.432503%\tTime: 9.08s\n",
            "Epoch #139\tLoss: 1.44096875\tTrain Acc: 98.262481%\tValid Acc: 97.477118%\tTime: 9.11s\n",
            "<=============== Learning Rate 0.00013717421124828533 -> 4.5724737082761774e-05===== ==========>\n",
            "Epoch #140\tLoss: 1.44370997\tTrain Acc: 98.181344%\tValid Acc: 97.411646%\tTime: 9.13s\n",
            "Epoch #141\tLoss: 1.44710767\tTrain Acc: 98.259245%\tValid Acc: 97.483926%\tTime: 9.09s\n",
            "Epoch #142\tLoss: 1.40599084\tTrain Acc: 98.201383%\tValid Acc: 97.444244%\tTime: 9.14s\n",
            "Epoch #143\tLoss: 1.43147361\tTrain Acc: 98.252788%\tValid Acc: 97.477907%\tTime: 9.08s\n",
            "Epoch #144\tLoss: 1.45124936\tTrain Acc: 98.211065%\tValid Acc: 97.408212%\tTime: 9.13s\n",
            "Epoch #145\tLoss: 1.48163724\tTrain Acc: 98.292045%\tValid Acc: 97.505553%\tTime: 9.14s\n",
            "/content/gdrive/MyDrive/Segmentation/check_points/Epoch145_loss1.4816_trainacc98.292_valacc97.506.pth\n",
            "Epoch #146\tLoss: 1.40745938\tTrain Acc: 98.222545%\tValid Acc: 97.466838%\tTime: 9.25s\n",
            "Epoch #147\tLoss: 1.48855674\tTrain Acc: 98.214264%\tValid Acc: 97.431536%\tTime: 9.29s\n",
            "Epoch #148\tLoss: 1.43101251\tTrain Acc: 98.222138%\tValid Acc: 97.460938%\tTime: 9.13s\n",
            "Epoch #149\tLoss: 1.45053911\tTrain Acc: 98.190402%\tValid Acc: 97.425162%\tTime: 9.13s\n",
            "Epoch #150\tLoss: 1.47649384\tTrain Acc: 98.254281%\tValid Acc: 97.463562%\tTime: 9.13s\n",
            "Epoch #151\tLoss: 1.41417396\tTrain Acc: 98.243122%\tValid Acc: 97.501389%\tTime: 9.16s\n",
            "Epoch #152\tLoss: 1.44235551\tTrain Acc: 98.273261%\tValid Acc: 97.473330%\tTime: 9.12s\n",
            "Epoch #153\tLoss: 1.41840672\tTrain Acc: 98.202648%\tValid Acc: 97.443711%\tTime: 9.11s\n",
            "Epoch #154\tLoss: 1.43985987\tTrain Acc: 98.217332%\tValid Acc: 97.469205%\tTime: 9.13s\n",
            "Epoch #155\tLoss: 1.47640324\tTrain Acc: 98.205782%\tValid Acc: 97.424768%\tTime: 9.13s\n",
            "Epoch #156\tLoss: 1.42327416\tTrain Acc: 98.230251%\tValid Acc: 97.473921%\tTime: 9.12s\n",
            "Epoch #157\tLoss: 1.47405791\tTrain Acc: 98.209996%\tValid Acc: 97.443494%\tTime: 9.13s\n",
            "Epoch #158\tLoss: 1.47132838\tTrain Acc: 98.200601%\tValid Acc: 97.396570%\tTime: 9.14s\n",
            "Epoch #159\tLoss: 1.46881545\tTrain Acc: 98.196099%\tValid Acc: 97.495884%\tTime: 9.16s\n",
            "<=============== Learning Rate 4.5724737082761774e-05 -> 1.5241579027587257e-05===== ==========>\n",
            "Epoch #160\tLoss: 1.45507097\tTrain Acc: 98.246467%\tValid Acc: 97.479091%\tTime: 9.15s\n",
            "Epoch #161\tLoss: 1.45675826\tTrain Acc: 98.240205%\tValid Acc: 97.496791%\tTime: 9.11s\n",
            "Epoch #162\tLoss: 1.44218314\tTrain Acc: 98.213710%\tValid Acc: 97.455847%\tTime: 9.10s\n",
            "Epoch #163\tLoss: 1.44969428\tTrain Acc: 98.207101%\tValid Acc: 97.462181%\tTime: 9.08s\n",
            "Epoch #164\tLoss: 1.46946466\tTrain Acc: 98.243789%\tValid Acc: 97.488346%\tTime: 9.12s\n",
            "Epoch #165\tLoss: 1.43590283\tTrain Acc: 98.225375%\tValid Acc: 97.479604%\tTime: 9.12s\n",
            "Epoch #166\tLoss: 1.44451952\tTrain Acc: 98.248742%\tValid Acc: 97.494917%\tTime: 9.17s\n",
            "Epoch #167\tLoss: 1.44556630\tTrain Acc: 98.240243%\tValid Acc: 97.504685%\tTime: 9.14s\n",
            "Epoch #168\tLoss: 1.44083989\tTrain Acc: 98.302276%\tValid Acc: 97.530929%\tTime: 9.13s\n",
            "Epoch #169\tLoss: 1.40444624\tTrain Acc: 98.252733%\tValid Acc: 97.480966%\tTime: 9.13s\n",
            "Epoch #170\tLoss: 1.44283390\tTrain Acc: 98.265712%\tValid Acc: 97.516761%\tTime: 9.14s\n",
            "Epoch #171\tLoss: 1.49653685\tTrain Acc: 98.217012%\tValid Acc: 97.452235%\tTime: 9.16s\n",
            "Epoch #172\tLoss: 1.43797457\tTrain Acc: 98.234422%\tValid Acc: 97.462437%\tTime: 9.12s\n",
            "Epoch #173\tLoss: 1.42664540\tTrain Acc: 98.255335%\tValid Acc: 97.475974%\tTime: 9.14s\n",
            "Epoch #174\tLoss: 1.39869010\tTrain Acc: 98.249676%\tValid Acc: 97.485386%\tTime: 9.15s\n",
            "Epoch #175\tLoss: 1.43879294\tTrain Acc: 98.245772%\tValid Acc: 97.486491%\tTime: 9.10s\n",
            "Epoch #176\tLoss: 1.46628237\tTrain Acc: 98.250903%\tValid Acc: 97.490161%\tTime: 9.12s\n",
            "Epoch #177\tLoss: 1.46490037\tTrain Acc: 98.216822%\tValid Acc: 97.432957%\tTime: 9.15s\n",
            "Epoch #178\tLoss: 1.48097730\tTrain Acc: 98.178423%\tValid Acc: 97.389900%\tTime: 9.14s\n",
            "Epoch #179\tLoss: 1.44495475\tTrain Acc: 98.288857%\tValid Acc: 97.513959%\tTime: 9.11s\n",
            "<=============== Learning Rate 1.5241579027587256e-05 -> 5.0805263425290855e-06===== ==========>\n",
            "Epoch #180\tLoss: 1.47276366\tTrain Acc: 98.269275%\tValid Acc: 97.513091%\tTime: 9.13s\n",
            "Epoch #181\tLoss: 1.43046975\tTrain Acc: 98.191353%\tValid Acc: 97.414388%\tTime: 9.10s\n",
            "Epoch #182\tLoss: 1.45139086\tTrain Acc: 98.188567%\tValid Acc: 97.420190%\tTime: 9.12s\n",
            "Epoch #183\tLoss: 1.52368283\tTrain Acc: 98.218945%\tValid Acc: 97.433924%\tTime: 9.16s\n",
            "Epoch #184\tLoss: 1.45864272\tTrain Acc: 98.261428%\tValid Acc: 97.507684%\tTime: 9.13s\n",
            "Epoch #185\tLoss: 1.43610418\tTrain Acc: 98.255813%\tValid Acc: 97.495292%\tTime: 9.12s\n",
            "Epoch #186\tLoss: 1.42435586\tTrain Acc: 98.276074%\tValid Acc: 97.531679%\tTime: 9.13s\n",
            "Epoch #187\tLoss: 1.45897949\tTrain Acc: 98.226569%\tValid Acc: 97.461431%\tTime: 9.17s\n",
            "Epoch #188\tLoss: 1.42420471\tTrain Acc: 98.228112%\tValid Acc: 97.499179%\tTime: 9.10s\n",
            "Epoch #189\tLoss: 1.53685093\tTrain Acc: 98.256638%\tValid Acc: 97.482584%\tTime: 9.12s\n",
            "Epoch #190\tLoss: 1.44633245\tTrain Acc: 98.237827%\tValid Acc: 97.473921%\tTime: 9.15s\n",
            "Epoch #191\tLoss: 1.49208438\tTrain Acc: 98.255003%\tValid Acc: 97.484873%\tTime: 9.11s\n",
            "Epoch #192\tLoss: 1.42611039\tTrain Acc: 98.223724%\tValid Acc: 97.452867%\tTime: 9.12s\n",
            "Epoch #193\tLoss: 1.44769084\tTrain Acc: 98.208106%\tValid Acc: 97.464114%\tTime: 9.13s\n",
            "Epoch #194\tLoss: 1.44339705\tTrain Acc: 98.214085%\tValid Acc: 97.466107%\tTime: 9.15s\n",
            "Epoch #195\tLoss: 1.47700119\tTrain Acc: 98.288325%\tValid Acc: 97.569585%\tTime: 9.16s\n",
            "Epoch #196\tLoss: 1.44734502\tTrain Acc: 98.194579%\tValid Acc: 97.437219%\tTime: 9.14s\n",
            "Epoch #197\tLoss: 1.46368623\tTrain Acc: 98.244653%\tValid Acc: 97.464884%\tTime: 9.12s\n",
            "Epoch #198\tLoss: 1.46019924\tTrain Acc: 98.213786%\tValid Acc: 97.462023%\tTime: 9.18s\n",
            "Epoch #199\tLoss: 1.45371199\tTrain Acc: 98.217772%\tValid Acc: 97.471119%\tTime: 9.09s\n",
            "<=============== Learning Rate 5.0805263425290855e-06 -> 1.6935087808430284e-06===== ==========>\n",
            "Epoch #200\tLoss: 1.45761657\tTrain Acc: 98.230311%\tValid Acc: 97.456123%\tTime: 9.15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFPd1NUP1nmI"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}